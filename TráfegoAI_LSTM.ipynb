{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MatheusCarneir0/ADS/blob/main/Tr%C3%A1fegoAI_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Google Drive"
      ],
      "metadata": {
        "id": "gHRKesfGijNX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQz2xCylWYyQ",
        "outputId": "06df8b85-eef8-479b-ecb5-eeb38203b1fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Bibliotecas principais"
      ],
      "metadata": {
        "id": "ETe98W9tiq6T"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-a_RGUNFW40g",
        "outputId": "6d466676-969c-49b4-b074-7554023f7b9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Usando dispositivo: cpu\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Usa GPU se disponível, senão CPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Usando dispositivo: {device}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Carregar e preparar os dados"
      ],
      "metadata": {
        "id": "a6W0z-beivZL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "0R7QooZtW6Et"
      },
      "outputs": [],
      "source": [
        "def carregar_e_preparar_dados(caminho_csv):\n",
        "    # 1) Lê o CSV\n",
        "    df = pd.read_csv(caminho_csv)\n",
        "\n",
        "    # 2) Normaliza nomes: tira espaços, deixa minúsculo, substitui espaços por underline\n",
        "    #    e remove caracteres especiais (exceto letras acentuadas, que \\w preserva)\n",
        "    df.columns = (\n",
        "        df.columns\n",
        "          .str.strip()\n",
        "          .str.lower()\n",
        "          .str.replace(' ', '_')\n",
        "          .str.replace(r'[^\\w]', '', regex=True)\n",
        "    )\n",
        "\n",
        "    # DEBUG: mostra as colunas pós-normalização\n",
        "    print(\"Colunas após limpeza:\", df.columns.tolist())\n",
        "\n",
        "    # 3) Converte 'data' para datetime e 'hora' para inteiro (pode gerar NaN se não for convertível)\n",
        "    df['data'] = pd.to_datetime(df['data'], dayfirst=True)\n",
        "    df['hora'] = pd.to_numeric(df['hora'], errors='coerce').astype('Int64')\n",
        "    df = df.dropna(subset=['hora'])  # remove linhas onde 'hora' não era numérico\n",
        "\n",
        "    # 4) Cria coluna 'data_hora'\n",
        "    df['data_hora'] = pd.to_datetime(\n",
        "        df['data'].dt.strftime('%Y-%m-%d') + ' ' + df['hora'].astype(str) + ':00:00'\n",
        "    )\n",
        "\n",
        "    # 5) Converte 'quantidade' para numérico e remove NaNs\n",
        "    df['quantidade'] = pd.to_numeric(df['quantidade'], errors='coerce')\n",
        "    df = df.dropna(subset=['quantidade'])\n",
        "\n",
        "    # 6) Agrupa por data_hora, km e veículo (com acento), somando as quantidades\n",
        "    #    Aqui usamos exatamente a coluna 'veículo' (o nome resultante após df.columns...)\n",
        "    #    Se quiser confirmar, verifique df.columns antes de rodar esta linha\n",
        "    dados_hora = (\n",
        "        df\n",
        "        .groupby(['data_hora', 'km', 'veículo'])['quantidade']\n",
        "        .sum()\n",
        "        .reset_index()\n",
        "        .sort_values('data_hora')\n",
        "    )\n",
        "\n",
        "    return dados_hora\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Dataset customizado"
      ],
      "metadata": {
        "id": "qNzjNeg0i92P"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "_6cfT6E6bJqC"
      },
      "outputs": [],
      "source": [
        "class TrafegoDataset(Dataset):\n",
        "    def __init__(self, df, seq_len=24):\n",
        "        self.seq_len = seq_len\n",
        "        self.samples = []\n",
        "\n",
        "        # Para cada par (km, veículo) → atenção ao nome 'veículo'\n",
        "        for (km, tipo), grupo in df.groupby(['km', 'veículo']):\n",
        "            valores = grupo['quantidade'].tolist()\n",
        "            # Se houver pelo menos seq_len+1 pontos, criamos as janelas\n",
        "            if len(valores) > seq_len:\n",
        "                for i in range(len(valores) - seq_len):\n",
        "                    x_seq = valores[i:i+seq_len]    # seq_len horas de input\n",
        "                    y_next = valores[i+seq_len]     # próxima hora como alvo\n",
        "                    self.samples.append((x_seq, y_next))\n",
        "            # Se não houver dados suficientes, pulamos esse grupo\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x, y = self.samples[idx]\n",
        "        # x: lista de seq_len floats → tensor [seq_len, 1]\n",
        "        x = torch.tensor(x, dtype=torch.float32).unsqueeze(-1)\n",
        "        y = torch.tensor(y, dtype=torch.float32)\n",
        "        return x, y\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Modelo LSTM simples"
      ],
      "metadata": {
        "id": "_DsXon40jOlO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "uSp40w3DbLg3"
      },
      "outputs": [],
      "source": [
        "class ModeloLSTM(nn.Module):\n",
        "    def __init__(self, input_size=1, hidden_size=64, num_layers=1):\n",
        "        super().__init__()\n",
        "        # LSTM: input_size=1 (uma feature: quantidade hora a hora)\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        # Camada final: transforma hidden_size → 1 valor de saída\n",
        "        self.fc = nn.Linear(hidden_size, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x tem shape [batch_size, seq_len, input_size]\n",
        "        out, _ = self.lstm(x)        # out: [batch_size, seq_len, hidden_size]\n",
        "        out = out[:, -1, :]           # pega o último passo: [batch_size, hidden_size]\n",
        "        out = self.fc(out)            # [batch_size, 1]\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Função de treino"
      ],
      "metadata": {
        "id": "E6C_bjoQjUfT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "NkU3__4UbN6e"
      },
      "outputs": [],
      "source": [
        "def treinar_modelo(df, epocas=10, batch_size=32, seq_len=24):\n",
        "    # 1) Verifica se o DataFrame está vazio\n",
        "    if df is None or df.empty:\n",
        "        print(\"❌ DataFrame vazio. Abortando treino.\")\n",
        "        return None\n",
        "\n",
        "    # 2) Cria o dataset e checa se há amostras\n",
        "    dataset = TrafegoDataset(df, seq_len)\n",
        "    if len(dataset) == 0:\n",
        "        print(f\"❌ Não há amostras para seq_len={seq_len}.\")\n",
        "        return None\n",
        "\n",
        "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    # 3) Instancia o modelo, a loss e o otimizador\n",
        "    modelo = ModeloLSTM().to(device)\n",
        "    criterio = nn.MSELoss()\n",
        "    otimizador = torch.optim.Adam(modelo.parameters(), lr=0.001)\n",
        "\n",
        "    # 4) Loop de treino\n",
        "    for ep in range(epocas):\n",
        "        modelo.train()\n",
        "        loss_total = 0.0\n",
        "\n",
        "        for x_batch, y_batch in loader:\n",
        "            x_batch = x_batch.to(device)  # [batch_size, 24, 1]\n",
        "            y_batch = y_batch.to(device)  # [batch_size]\n",
        "\n",
        "            otimizador.zero_grad()\n",
        "            pred = modelo(x_batch).squeeze()    # [batch_size,1] → squeeze() → [batch_size]\n",
        "            loss = criterio(pred, y_batch)\n",
        "            loss.backward()\n",
        "            otimizador.step()\n",
        "\n",
        "            loss_total += loss.item()\n",
        "\n",
        "        print(f'Época {ep+1}/{epocas} — Loss: {loss_total:.4f}')\n",
        "\n",
        "    return modelo\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ex-Zl8Tornqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Código principal"
      ],
      "metadata": {
        "id": "gV-R-7SPjXo1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOKoTGARbQ7w",
        "outputId": "f2ff9cf5-9fde-42f2-b51f-772f77cee5cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Colunas após limpeza: ['data', 'hora', 'sentido', 'uf', 'br', 'km', 'ano', 'classe', 'quantidade', 'latitude', 'longitude', 'veículo']\n",
            "Época 1/10 — Loss: 98238638.9463\n",
            "Época 2/10 — Loss: 38891768.1128\n",
            "Época 3/10 — Loss: 26475747.1089\n",
            "Época 4/10 — Loss: 18213947.6388\n",
            "Época 5/10 — Loss: 13870399.8671\n",
            "Época 6/10 — Loss: 10091995.1315\n",
            "Época 7/10 — Loss: 9736726.2847\n",
            "Época 8/10 — Loss: 8532206.2834\n",
            "Época 9/10 — Loss: 8979919.1548\n",
            "Época 10/10 — Loss: 8491020.9888\n",
            "✅ Modelo salvo em 'modelo_lstm_trafego.pth'\n"
          ]
        }
      ],
      "source": [
        "# 1) Montar o Google Drive (se ainda não montou)\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "except Exception:\n",
        "    print(\"Não está no Colab ou o Drive já está montado.\")\n",
        "\n",
        "# 2) Defina o caminho do arquivo no Drive\n",
        "CAMINHO = '/content/drive/MyDrive/TráfegoAI/Dados processados/020_CE_formatado_completo.csv'\n",
        "\n",
        "# 3) Carrega e prepara os dados\n",
        "df = carregar_e_preparar_dados(CAMINHO)\n",
        "\n",
        "# 4) Treina o modelo\n",
        "modelo = treinar_modelo(df, epocas=10, batch_size=32, seq_len=24)\n",
        "\n",
        "# 5) Se o treino foi bem-sucedido, salva os pesos\n",
        "if modelo is not None:\n",
        "    torch.save(modelo.state_dict(), 'modelo_lstm_trafego.pth')\n",
        "    print(\"✅ Modelo salvo em 'modelo_lstm_trafego.pth'\")\n",
        "else:\n",
        "    print(\"❌ Treino falhou ou dataset não continha amostras suficientes.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Teste**"
      ],
      "metadata": {
        "id": "1HCtV7CBjf7b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " # 3) Carrega e prepara os dados\n",
        "df = carregar_e_preparar_dados(CAMINHO)\n",
        "# ---------------------------------------------------\n",
        "#     BLOCO DE DEBUG: INVESTIGANDO O DATAFRAME\n",
        "# ---------------------------------------------------\n",
        "\n",
        "# 1. Imprime as primeiras linhas para ver a estrutura\n",
        "print(\"=== As 10 primeiras linhas de df ===\")\n",
        "print(df.head(10))\n",
        "\n",
        "# 2. Quantos registros existem por KM?\n",
        "print(\"\\n=== Quantidade de registros por km ===\")\n",
        "print(df['km'].value_counts().sort_index().head(10), \"… (se aparecer '…', há mais km que não cabem aqui)\")\n",
        "\n",
        "# 3. Quais tipos de veículo existem no total?\n",
        "print(\"\\n=== Lista completa de tipos de veículo (únicos) ===\")\n",
        "print(df['veículo'].unique())\n",
        "\n",
        "# 4. Para um KM específico (por exemplo 80.2), veja que tipos de veículo aparecem:\n",
        "km_exemplo = 80.2\n",
        "tipos_no_km = df[df['km'] == km_exemplo]['veículo'].unique()\n",
        "print(f\"\\n=== Tipos de veículo disponíveis para km = {km_exemplo} ===\")\n",
        "print(tipos_no_km)\n",
        "\n",
        "# 5. Para cada (km, tipo_veículo), quantos registros há?\n",
        "print(\"\\n=== Exemplos de contagem de registros por (km,veículo) ===\")\n",
        "counts = df.groupby(['km', 'veículo']).size().reset_index(name='contador')\n",
        "print(counts.head(10), \"…\")\n",
        "# ---------------------------------------------------\n",
        "#        FIM DO BLOCO DE DEBUG\n",
        "# ---------------------------------------------------\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lp7CLPtnzHdn",
        "outputId": "6fa78eea-fa34-495d-b9cf-7e06f3d30a81"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colunas após limpeza: ['data', 'hora', 'sentido', 'uf', 'br', 'km', 'ano', 'classe', 'quantidade', 'latitude', 'longitude', 'veículo']\n",
            "=== As 10 primeiras linhas de df ===\n",
            "   data_hora    km                                            veículo  \\\n",
            "0 2021-09-01   401    Caminhão + Reboque ou 2 Semirreboques (5 eixos)   \n",
            "1 2021-09-01   401  Caminhão + Reboque ou Semirreboque + Reboque (...   \n",
            "2 2021-09-01   401                                         Indefinido   \n",
            "3 2021-09-01   401                  Veículos de Passeio / Utilitários   \n",
            "4 2021-09-01   401                Ônibus / Caminhão Simples (2 eixos)   \n",
            "5 2021-09-01   401                Ônibus / Caminhão Simples (3 eixos)   \n",
            "6 2021-09-01  80,2     Caminhão + 2 Semirreboques + Reboque (9 eixos)   \n",
            "7 2021-09-01  80,2  Caminhão + Reboque ou Semirreboque + Reboque (...   \n",
            "8 2021-09-01  80,2                  Veículos de Passeio / Utilitários   \n",
            "9 2021-09-01  80,2                Ônibus / Caminhão Simples (3 eixos)   \n",
            "\n",
            "   quantidade  \n",
            "0           1  \n",
            "1           1  \n",
            "2           1  \n",
            "3          10  \n",
            "4           5  \n",
            "5           5  \n",
            "6           1  \n",
            "7           1  \n",
            "8           2  \n",
            "9           3  \n",
            "\n",
            "=== Quantidade de registros por km ===\n",
            "km\n",
            "401       133319\n",
            "411,41     68593\n",
            "80,2      132477\n",
            "Name: count, dtype: int64 … (se aparecer '…', há mais km que não cabem aqui)\n",
            "\n",
            "=== Lista completa de tipos de veículo (únicos) ===\n",
            "['Caminhão + Reboque ou 2 Semirreboques (5 eixos)'\n",
            " 'Caminhão + Reboque ou Semirreboque + Reboque (6 eixos)' 'Indefinido'\n",
            " 'Veículos de Passeio / Utilitários' 'Ônibus / Caminhão Simples (2 eixos)'\n",
            " 'Ônibus / Caminhão Simples (3 eixos)'\n",
            " 'Caminhão + 2 Semirreboques + Reboque (9 eixos)'\n",
            " 'Caminhão + Reboque + 2 Semirreboques (7 eixos)' 'Motocicletas'\n",
            " 'Caminhão + 2 Semirreboques (8 eixos)']\n",
            "\n",
            "=== Tipos de veículo disponíveis para km = 80.2 ===\n",
            "[]\n",
            "\n",
            "=== Exemplos de contagem de registros por (km,veículo) ===\n",
            "    km                                            veículo  contador\n",
            "0  401               Caminhão + 2 Semirreboques (8 eixos)       787\n",
            "1  401     Caminhão + 2 Semirreboques + Reboque (9 eixos)     10354\n",
            "2  401     Caminhão + Reboque + 2 Semirreboques (7 eixos)      7371\n",
            "3  401    Caminhão + Reboque ou 2 Semirreboques (5 eixos)     11874\n",
            "4  401  Caminhão + Reboque ou Semirreboque + Reboque (...     13985\n",
            "5  401                                         Indefinido     15062\n",
            "6  401                                       Motocicletas     18026\n",
            "7  401                  Veículos de Passeio / Utilitários     18797\n",
            "8  401                Ônibus / Caminhão Simples (2 eixos)     18728\n",
            "9  401                Ônibus / Caminhão Simples (3 eixos)     18335 …\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# a) Reconstrói a arquitetura\n",
        "modelo_carregado = ModeloLSTM().to(device)\n",
        "\n",
        "# b) Carrega os pesos (com map_location para lidar com CPU/GPU)\n",
        "try:\n",
        "    modelo_carregado.load_state_dict(torch.load('modelo_lstm_trafego.pth', map_location=device))\n",
        "    modelo_carregado.eval()\n",
        "    print(\"✅ Modelo carregado e pronto para inferência\")\n",
        "except FileNotFoundError:\n",
        "    print(\"❌ Arquivo 'modelo_lstm_trafego.pth' não encontrado.\")\n",
        "except Exception as e:\n",
        "    print(\"❌ Erro ao carregar o modelo:\", e)\n",
        "\n",
        "# c) Exemplo de previsão (se o modelo foi carregado com sucesso)\n",
        "if hasattr(modelo_carregado, 'eval'):\n",
        "    # Escolha um KM e um tipo de veículo existentes no df\n",
        "    target_km = 80.2\n",
        "\n",
        "    # MOSTRA ALGUNS TIPOS para você escolher\n",
        "    print(\"Tipos de veículo disponíveis (alguns exemplos):\", df['veículo'].unique()[:5], \"…\")\n",
        "\n",
        "    # Use exatamente um dos valores listados acima\n",
        "    target_tipo = df['veículo'].unique()[0]\n",
        "    seq_len = 24\n",
        "\n",
        "    # Filtra todas as linhas para esse KM e tipo, ordenadas por data_hora\n",
        "    grupo_filtrado = df[(df['km'] == target_km) & (df['veículo'] == target_tipo)] \\\n",
        "                      .sort_values('data_hora')\n",
        "\n",
        "    print(f\"Total de registros encontrados para KM {target_km}, Tipo '{target_tipo}': {len(grupo_filtrado)}\")\n",
        "\n",
        "    # Pega as últimas 24 horas\n",
        "    grupo_ultimo = grupo_filtrado.tail(seq_len)\n",
        "    print(f\"Número de linhas após .tail({seq_len}): {len(grupo_ultimo)}\")\n",
        "\n",
        "    if len(grupo_ultimo) == seq_len:\n",
        "        entrada = torch.tensor(grupo_ultimo['quantidade'].tolist(), dtype=torch.float32) \\\n",
        "                     .unsqueeze(0).unsqueeze(-1).to(device)  # [1,24,1]\n",
        "        with torch.no_grad():\n",
        "            previsao = modelo_carregado(entrada).item()\n",
        "        print(f\"Previsão próxima hora (KM {target_km}, Tipo '{target_tipo}'): {previsao:.2f}\")\n",
        "    else:\n",
        "        print(f\"❌ Não há {seq_len} horas completas para KM {target_km}, Tipo '{target_tipo}'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4PAPS7amPxv",
        "outputId": "1daf1045-d7ee-4115-be9d-66d08b3df43c"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Modelo carregado e pronto para inferência\n",
            "Tipos de veículo disponíveis (alguns exemplos): ['Caminhão + Reboque ou 2 Semirreboques (5 eixos)'\n",
            " 'Caminhão + Reboque ou Semirreboque + Reboque (6 eixos)' 'Indefinido'\n",
            " 'Veículos de Passeio / Utilitários' 'Ônibus / Caminhão Simples (2 eixos)'] …\n",
            "Total de registros encontrados para KM 80.2, Tipo 'Caminhão + Reboque ou 2 Semirreboques (5 eixos)': 0\n",
            "Número de linhas após .tail(24): 0\n",
            "❌ Não há 24 horas completas para KM 80.2, Tipo 'Caminhão + Reboque ou 2 Semirreboques (5 eixos)'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ef1fiKA_nmeA"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNtnR4RYevfONCIIEXky556",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}